# ForceTouchDetection 

This repository contains the data and model for the MobileHCI '19 LBR paper on "Force Touch Detection on Capacitive Sensors using Deep Neural Networks".

## Abstract
As the touchscreen is the most successful input method of current mobile devices, the importance to transmit more in- formation per touch is raising. A wide range of approaches has been presented to enhance the richness of a single touch. With Apple’s 3D Touch, they successfully introduce pressure as a new input dimension into consumer devices. However, they are using a new sensing layer, which in- creases production cost and hardware complexity. More- over, users have to upgrade their phones to use the new feature. In contrast, with this work, we introduce a strategy to acquire the pressure measurements from the mutual capacitive sensor, which is used in the majority of today’s touch devices. We present a data collection study in which we collect capacitive images where participants apply different pressure levels. We then train a Deep Neural Network (DNN) to estimate the pressure allowing for force touch detection. As a result, we present a model which enables estimating the pressure with a mean error of 369.0g.

## How to cite this work

This work can be cited as follows:
<pre>
@inproceedings{Boceck:2019:PressureTouch,
title = {Force Touch Detection on Capacitive Sensors using Deep Neural Networks},
author = {Boceck, Tobias and Sprott, Sascha and Le, Huy Viet and Mayer, Sven},
year = {2019},
date = {2019-10-01},
booktitle = {Proceedings of the 21st International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
publisher = {ACM},
address = {New York, NY, USA},
series = {MobileHCI '19}
}
</pre>
